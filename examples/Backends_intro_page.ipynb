{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70b0bc3-2244-4426-b464-1fbadcc237f1",
   "metadata": {},
   "source": [
    "# Selecting a Backend (needs links in noisy section)\n",
    "\n",
    "CUDA-Q provides a number of options for running your quantum algorithms ranging from integrations with physical QPU providers to specialized simulators. This section will help you select which option is best for you.  The flowchart below is a helpful starting place, followed by a description of each backend and what sorts of applications might benefit from each.  The sections below will not provide exhaustive details on how to use each backend, but will link to the appropriate sections in the documentation. \n",
    "\n",
    "Each option in the flowchart can be specified in your code with `cudaq.set_target(\"nvidia\")`, using the `nvidia` backend as an example. \n",
    "\n",
    "\n",
    "\n",
    "![Htest](../images/backends.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8849234-7ba9-476b-addd-f04a09a0ff96",
   "metadata": {},
   "source": [
    "### Physical QPU Backends\n",
    "\n",
    "CUDA-Q is integrated with a number of physical QPU providers:\n",
    "1. [IonQ](https://nvidia.github.io/cuda-quantum/latest/using/backends/hardware.html#ionq) - Trapped Ion\n",
    "2. [IQM](https://nvidia.github.io/cuda-quantum/latest/using/backends/hardware.html#iqm) - Superconducting\n",
    "3. [OQC](https://nvidia.github.io/cuda-quantum/latest/using/backends/hardware.html#oqc) - Superconducting\n",
    "4. [Orca](https://nvidia.github.io/cuda-quantum/latest/using/backends/hardware.html#orca-computing) Computing - Photonic\n",
    "5. [Quantinuum](https://nvidia.github.io/cuda-quantum/latest/using/backends/hardware.html#quantinuum) - Trapped Ion\n",
    "\n",
    "If you have access to any of these providers, you can simply enter your credentials and target them as a backend. You can target specific devices or emulators from each provider.  Please click on provider to link to more information and code examples for how to use each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2fbf5-5a71-490a-8ee5-6a3b6df056a4",
   "metadata": {},
   "source": [
    "### Noiseless GPU Accelerated State Vector Simulators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f0c72-eb92-433b-a2d8-29a7d7bfd793",
   "metadata": {},
   "source": [
    "If you have access to an NVIDIA GPU, you will likely use the `nvidia` backend for most simulations.  This backend make immediate use of the GPU to accelerate any state vector simulation.  The NVIDIA backend can provide massive acceleration for even modest circuit sizes and simulate any circuit that can fit in a single GPU. More details can be found [here](https://nvidia.github.io/cuda-quantum/latest/using/backends/simulators.html#nvidia-backend), for advanced options like specifying the floating-point precision you would like to use.\n",
    "\n",
    "\n",
    "If you have access to more than one GPU, you can use them in a couple of ways to scale your computations.  First, the `nvidia-mgpu` backend can be used to pool the memory of multiple GPUs to increase the size of the state vector you an run. (Documentation found [here](https://nvidia.github.io/cuda-quantum/latest/using/backends/simulators.html#nvidia-mgpu-backend)) For an example of an application that uses `nvidia-mgpu` for a divisive clustering problem, click [here](https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/Divisive_clustering.html).\n",
    "\n",
    "Another option is the `nvidia-mqpu` backend which simulates the function of multiple QPUs running asynchronously.  This is extremely helpful for tasks that can be parallelized, like batching Hamiltonian terms for a VQE simulation, or computing parameter shift gradients.  Code that effectively uses the MQPU backend can be trivially deployed on future systems which have access to multiple QPUs. (Documentation found [here](https://nvidia.github.io/cuda-quantum/latest/using/backends/platform.html#mqpu-platform)) For an example of an application that uses `nvidia-mqpu` for a Hadamard test chemistry problem, click [here](https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/hadamard_test.html).\n",
    "\n",
    "Finally, the `remote-mqpu` backend can be used to combine the capabilities of MGPU and MQPU, and simulate multiple QPUs for problems which require memory from more than one GPU. \n",
    "\n",
    "![Htest](../images/mqpumgpu.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca404d5-213f-41e8-a76d-14cfd83ddd5d",
   "metadata": {},
   "source": [
    "### Noisy State Vector Simulations\n",
    "\n",
    "You can add noise to your simulations using the `density-matrix-cpu` backend.  This allows you to construct custom and predefined noise models and simulate their effect on your applications. This is particularly useful for studying error correction and mitigation techniques.  For more information on noisy model, see THIS section of the docs as well as THIS application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985ef3d-fa05-4f9e-a640-7ee3e50e3a8f",
   "metadata": {},
   "source": [
    "### Tensor Network Simulations\n",
    "\n",
    "Tensor network simulations are are a useful alternative to state vector simulations. Generally, Tensor networks are appropriate for shallow and low entanglement circuits, but can enable simulation of much larger qubit numbers.  The `tensornet` backend is used to run an exact tensor network simulation with support for mult-node multi-GPU acceleration.  Documentation can be found [here](https://nvidia.github.io/cuda-quantum/latest/using/backends/simulators.html#tensor-backends).\n",
    "\n",
    "\n",
    "The `tensornet-mps` backend performs tensor network simulations with a matrix product state (MPS) approximation. This takes advantage of the sparsity present in a tensor network simulation and creates an approximate simulation based on common tensor decomposition techniques.  Documentation can be found [here](https://nvidia.github.io/cuda-quantum/latest/using/backends/simulators.html#matrix-product-state)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a2eeb-27df-4048-89de-74d3d6183783",
   "metadata": {},
   "source": [
    "### NVIDIA Quantum Cloud (NVQC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ad776-4ea5-4f33-8060-9c40b0682cfe",
   "metadata": {},
   "source": [
    "The NVIDIA quantum could provides remote GPU access for quantum developers.  Users can take advantage of NVIDIA's DGX-H100 systems to run their simulations if GPUs are not otherwise availible.  Sign up for NVQC access read about it in the docs [here](https://nvidia.github.io/cuda-quantum/latest/using/backends/nvqc.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
